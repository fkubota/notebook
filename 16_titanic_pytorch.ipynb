{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "- pytorch を使って titanic の問題を解く\n",
    "- data は、`15_pytorch_NN` 内にある\n",
    "- ref: \n",
    "    > https://kaeru-nantoka.hatenablog.com/entry/2019/03/30/003112"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything I need :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fastprogress import progress_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cuda?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "path = '15_pytorch_NN/train.csv'\n",
    "train = pd.read_csv(path)\n",
    "\n",
    "# test\n",
    "path = '15_pytorch_NN/test.csv'\n",
    "test = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['Survived'].values\n",
    "train = train.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed = 1337\n",
    "seed_everything(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape\n",
      "train: (891, 11)\n",
      "test:  (418, 11)\n"
     ]
    }
   ],
   "source": [
    "print(f'data shape')\n",
    "print(f'train: {train.shape}')\n",
    "print(f'test:  {test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "check null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "train.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "test.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FeatureEngineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NameとTicket,Cabin はいらないだろう"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def delete_name(df):\n",
    "    return df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "train = delete_name(train)\n",
    "test  = delete_name(test )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "カテゴリカル特徴量 と 数値特徴量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "カテゴリカル: ['Cabin', 'Embarked', 'Name', 'Sex', 'Ticket']\n",
      "数値:        ['Pclass', 'Age', 'Fare', 'SibSp', 'PassengerId', 'Parch']\n"
     ]
    }
   ],
   "source": [
    "cat_cols = ['Cabin','Embarked','Name','Sex','Ticket',]\n",
    "num_cols = list(set(train.columns) - set(cat_cols) - set([\"Survived\"]))\n",
    "print(f'カテゴリカル: {cat_cols}')\n",
    "print(f'数値:        {num_cols}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "ラベルエンコーディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(encoder, x):\n",
    "    len_encoder = len(encoder)\n",
    "    try:\n",
    "        id = encoder[x]\n",
    "    except KeyError:\n",
    "        id = len_encoder\n",
    "    return id\n",
    "\n",
    "encoders = [{} for cat in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding Cabin ... Done\n",
      "encoding Embarked ... Done\n",
      "encoding Name ... Done\n",
      "encoding Sex ... Done\n",
      "encoding Ticket ... Done\n"
     ]
    }
   ],
   "source": [
    "for i, cat in enumerate(cat_cols):\n",
    "    print('encoding %s ...' % cat, end=' ')\n",
    "    encoders[i] = {l: id for id, l in enumerate(train.loc[:, cat].astype(str).unique())}\n",
    "    train[cat] = train[cat].astype(str).apply(lambda x: encode(encoders[i], x))\n",
    "    test[cat]  =  test[cat].astype(str).apply(lambda x: encode(encoders[i], x))\n",
    "    print('Done')\n",
    "\n",
    "embed_sizes = [len(encoder) for encoder in encoders]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "数値特徴量を標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling numerical columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "train[num_cols] = train[num_cols].fillna(0)\n",
    "test[num_cols]  =  test[num_cols].fillna(0)\n",
    "print('scaling numerical columns')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train[num_cols] = scaler.fit_transform(train[num_cols])\n",
    "test[num_cols] = scaler.transform(test[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "学習データ・セット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train\n",
    "y = target\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class CustomLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True, p=0.5):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features, bias)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "net = nn.Sequential(CustomLinear(12, 32), nn.Linear(32, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- set params -----\n",
    "n_splits = 3\n",
    "batch_size = 20\n",
    "train_epochs = 15\n",
    "VERBOSE = 4\n",
    "# -----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# analysis\n",
    "def threshold_search(y_true, y_proba):\n",
    "    best_threshold = 0\n",
    "    best_score = 0\n",
    "    for threshold in progress_bar([i * 0.01 for i in range(100)]):\n",
    "        score = accuracy_score(y_true=y_true, y_pred=y_proba > threshold)\n",
    "        if score > best_score:\n",
    "            best_threshold = threshold\n",
    "            best_score = score\n",
    "    search_result = {'threshold': best_threshold, 'accuracy_score': best_score}\n",
    "    return search_result\n",
    "\n",
    "# Model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True, p=0.5):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features, bias)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "# net = Model(11, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 3\n",
    "folds = KFold(n_splits=n_splits, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "- Fold 1/3\n",
      "Epoch 4/15 \t loss=13.7243 \t val_loss=13.7243 \t time=0.02s\n",
      "Epoch 8/15 \t loss=13.7243 \t val_loss=13.7243 \t time=0.01s\n",
      "Epoch 12/15 \t loss=13.7243 \t val_loss=13.7243 \t time=0.01s\n",
      "Epoch 15/15 \t loss=13.7243 \t val_loss=13.7243 \t time=0.02s\n",
      "--------------------------------------------------\n",
      "- Fold 2/3\n",
      "Epoch 4/15 \t loss=13.9304 \t val_loss=13.8568 \t time=0.02s\n",
      "Epoch 8/15 \t loss=13.8028 \t val_loss=13.8413 \t time=0.01s\n",
      "Epoch 12/15 \t loss=13.8453 \t val_loss=13.8233 \t time=0.01s\n",
      "Epoch 15/15 \t loss=13.8032 \t val_loss=13.8095 \t time=0.01s\n",
      "--------------------------------------------------\n",
      "- Fold 3/3\n",
      "Epoch 4/15 \t loss=13.7069 \t val_loss=13.7194 \t time=0.02s\n",
      "Epoch 8/15 \t loss=13.7088 \t val_loss=13.7291 \t time=0.02s\n",
      "Epoch 12/15 \t loss=13.7117 \t val_loss=13.7244 \t time=0.01s\n",
      "Epoch 15/15 \t loss=13.6937 \t val_loss=13.7310 \t time=0.01s\n"
     ]
    }
   ],
   "source": [
    "# Kfold のループ部分\n",
    "train_preds = np.zeros((len(X)))\n",
    "test_preds = np.zeros((len(X_test)))\n",
    "for i, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
    "\n",
    "    # X, y, X_val, y_val をテンソル化(PyTorch で扱える形に変換)し、 .cuda() (GPUで計算するために特徴量を GPU に渡す処理)をする。\n",
    "    X_train_fold = torch.tensor(X.iloc[train_idx, :].values, dtype=torch.float32)\n",
    "    X_val_fold   = torch.tensor(X.iloc[valid_idx, :].values, dtype=torch.float32)\n",
    "    X_test_      = torch.tensor(X_test.iloc[:,:].values, dtype=torch.float32) \n",
    "    y_train_fold = torch.tensor(y[train_idx, np.newaxis], dtype=torch.float32)\n",
    "    y_val_fold   = torch.tensor(y[valid_idx, np.newaxis], dtype=torch.float32)\n",
    "    \n",
    "    # model を呼び出して、\n",
    "    model = Model(11, 1)\n",
    "    \n",
    "    # gpu 使えるならcudaに渡す\n",
    "    if is_cuda:\n",
    "        X_train_fold.cuda()\n",
    "        y_train_fold.cuda()\n",
    "        X_val_fold.cuda()\n",
    "        y_val_fold.cuda()\n",
    "    \n",
    "    # loss 関数を呼び出す。BCELoss() よりも好まれるらしい。。\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss(reduction=\"sum\")\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    # dataloader で扱える形( = Dataset )にする\n",
    "    train_ = torch.utils.data.TensorDataset(X_train_fold, y_train_fold)\n",
    "    valid_ = torch.utils.data.TensorDataset(X_val_fold, y_val_fold)\n",
    "    test_  = torch.utils.data.TensorDataset(X_test_)\n",
    "    \n",
    "    # X_train_fold batch_size個, y_train_fold batch_size個ずつを各ループで返す iterater の定義\n",
    "    train_loader = torch.utils.data.DataLoader(train_, batch_size=batch_size, shuffle=True)\n",
    "    # X_valid_fold batch_size個, y_valid_fold batch_size個ずつを各ループで返す iterater の定義\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_, batch_size=batch_size, shuffle=False)\n",
    "    # X_valid_fold batch_size個, y_valid_fold batch_size個ずつを各ループで返す iterater の定義\n",
    "    test_loader = torch.utils.data.DataLoader(test_, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print('-'*50)\n",
    "    print(f'- Fold {i + 1}/{n_splits}')\n",
    "    \n",
    "    # epoch 分のループを回す\n",
    "    for epoch in range(train_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # model を train mode にする\n",
    "        model.train()\n",
    "        avg_loss = 0.\n",
    "\n",
    "        # X_train_fold と y_train_fold を batch_size 個ずつ渡すループ\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            # predict\n",
    "            y_pred = model.forward(X_batch)\n",
    "            # loss の計算\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item() / len(train_loader)\n",
    "        \n",
    "        \n",
    "        # evaluate\n",
    "        if ((epoch+1)%VERBOSE==0) or (epoch+1==train_epochs):\n",
    "            model.eval()\n",
    "            valid_preds_fold = np.zeros((X_val_fold.size(0)))\n",
    "            test_preds_fold = np.zeros(len(X_test_))\n",
    "            avg_val_loss = 0.\n",
    "            for i, (X_batch, y_batch) in enumerate(valid_loader):\n",
    "                y_pred = model(X_batch).detach()\n",
    "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "                valid_preds_fold[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "\n",
    "            elapsed_time = time.time() - start_time \n",
    "            print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t time={:.2f}s'.format(\n",
    "                epoch + 1, train_epochs, avg_loss, avg_val_loss, elapsed_time))\n",
    "\n",
    "    # X_test_fold を batch_size ずつ渡すループ    \n",
    "    for i, (X_batch,) in enumerate(test_loader):\n",
    "        y_pred = model(X_batch).detach()\n",
    "\n",
    "        # batch_size のリストのリストになっているのを単一階層のリストに変換して、cpuに値を渡し、テンソルから numpy.array()に変換したものを sigmoid 関数に渡す\n",
    "        test_preds_fold[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "\n",
    "    train_preds[valid_idx] = valid_preds_fold\n",
    "\n",
    "    # 予測値の kfold数で割った値を加える\n",
    "    test_preds += test_preds_fold / n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='100' class='' max='100', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [100/100 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'threshold': 0.79, 'accuracy_score': 0.6161616161616161}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result = threshold_search(y, train_preds)\n",
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
